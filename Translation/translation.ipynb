{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73327,"databundleVersionId":8077727,"sourceType":"competition"},{"sourceId":1808362,"sourceType":"datasetVersion","datasetId":1074315}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":2110.49259,"end_time":"2024-03-29T13:27:37.876584","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-03-29T12:52:27.383994","version":"2.5.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RNN with attention for translation\n","metadata":{"papermill":{"duration":0.008842,"end_time":"2024-03-29T12:52:30.230002","exception":false,"start_time":"2024-03-29T12:52:30.221160","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Loading the data\n","metadata":{"papermill":{"duration":0.007997,"end_time":"2024-03-29T12:52:30.246243","exception":false,"start_time":"2024-03-29T12:52:30.238246","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv(\n    \"por.txt\",\n    sep=\"\\t\",\n    usecols=[0, 1],\n    names=[\"EN\", \"PR\"],\n)\ntrain_df.head()","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:30.265389Z","iopub.status.busy":"2024-03-29T12:52:30.264881Z","iopub.status.idle":"2024-03-29T12:52:31.765524Z","shell.execute_reply":"2024-03-29T12:52:31.764543Z"},"papermill":{"duration":1.513593,"end_time":"2024-03-29T12:52:31.767956","exception":false,"start_time":"2024-03-29T12:52:30.254363","status":"completed"},"tags":[]},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EN</th>\n","      <th>PR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Vai.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Go.</td>\n","      <td>Vá.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hi.</td>\n","      <td>Oi.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Run!</td>\n","      <td>Corre!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Run!</td>\n","      <td>Corra!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     EN      PR\n","0   Go.    Vai.\n","1   Go.     Vá.\n","2   Hi.     Oi.\n","3  Run!  Corre!\n","4  Run!  Corra!"]},"metadata":{}}]},{"cell_type":"markdown","source":"### Preprocess\n","metadata":{"papermill":{"duration":0.008308,"end_time":"2024-03-29T12:52:31.785677","exception":false,"start_time":"2024-03-29T12:52:31.777369","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import unicodedata\nimport re\n\n\ndef unicode2ascii(s):\n    return \"\".join(\n        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n    )\n\n\ndef normalize_string(s):\n    s = unicode2ascii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n    return s.strip()","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:31.803689Z","iopub.status.busy":"2024-03-29T12:52:31.803409Z","iopub.status.idle":"2024-03-29T12:52:31.809203Z","shell.execute_reply":"2024-03-29T12:52:31.808363Z"},"papermill":{"duration":0.017183,"end_time":"2024-03-29T12:52:31.811143","exception":false,"start_time":"2024-03-29T12:52:31.793960","status":"completed"},"tags":[]},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n\ndef preprocess(texts):\n    for text in tqdm(texts, desc=\"Building vocab\"):\n        tokens = normalize_string(str(text)).split()\n        yield tokens","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:31.829966Z","iopub.status.busy":"2024-03-29T12:52:31.829687Z","iopub.status.idle":"2024-03-29T12:52:31.844470Z","shell.execute_reply":"2024-03-29T12:52:31.843817Z"},"papermill":{"duration":0.027012,"end_time":"2024-03-29T12:52:31.846439","exception":false,"start_time":"2024-03-29T12:52:31.819427","status":"completed"},"tags":[]},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Create vocabs\n","metadata":{"papermill":{"duration":0.008017,"end_time":"2024-03-29T12:52:31.862813","exception":false,"start_time":"2024-03-29T12:52:31.854796","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from torchtext.vocab import build_vocab_from_iterator\n\nSPECIAL_TOKENS = [\"<SOS>\", \"<EOS>\", \"<UNK>\", \"<PAD>\"]\nenglish_vocab = build_vocab_from_iterator(\n    preprocess(train_df[\"EN\"].values), special_first=True, specials=SPECIAL_TOKENS\n)\n\nport_vocab = build_vocab_from_iterator(\n    preprocess(train_df[\"PR\"].values), special_first=True, specials=SPECIAL_TOKENS\n)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:31.880311Z","iopub.status.busy":"2024-03-29T12:52:31.880028Z","iopub.status.idle":"2024-03-29T12:52:46.398253Z","shell.execute_reply":"2024-03-29T12:52:46.396996Z"},"papermill":{"duration":14.529311,"end_time":"2024-03-29T12:52:46.400266","exception":false,"start_time":"2024-03-29T12:52:31.870955","status":"completed"},"tags":[]},"execution_count":4,"outputs":[{"name":"stderr","output_type":"stream","text":"Building vocab: 100%|██████████| 168903/168903 [00:04<00:00, 39251.91it/s]\n\nBuilding vocab: 100%|██████████| 168903/168903 [00:04<00:00, 35398.26it/s]\n"}]},{"cell_type":"code","source":"print(\"Length of english vocab:\", len(english_vocab))\nprint(\"Length of portugese vocab:\", len(port_vocab))","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:46.433119Z","iopub.status.busy":"2024-03-29T12:52:46.432658Z","iopub.status.idle":"2024-03-29T12:52:46.438393Z","shell.execute_reply":"2024-03-29T12:52:46.437569Z"},"papermill":{"duration":0.024177,"end_time":"2024-03-29T12:52:46.440557","exception":false,"start_time":"2024-03-29T12:52:46.416380","status":"completed"},"tags":[]},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"Length of english vocab: 12221\n\nLength of portugese vocab: 20582\n"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nSOS_TOKEN_IDX = english_vocab[\"<SOS>\"]\nEOS_TOKEN_IDX = english_vocab[\"<EOS>\"]\nMAX_LENGTH = 100\n\n\ndef sentence2idxs(vocab, sentence):\n    tokens = normalize_string(str(sentence)).split(\" \")\n    return [vocab[word] if word in vocab else vocab[\"<UNK>\"] for word in tokens]\n\n\ndef sentence2tensor(vocab, sentence):\n    indexes = sentence2idxs(vocab, sentence)\n    indexes.append(EOS_TOKEN_IDX)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\n\ndef process_sentence(vocab, sentence):\n    idxs = sentence2idxs(vocab, sentence)\n    idxs.append(EOS_TOKEN_IDX)\n    return idxs\n\n\ndef get_dataloader(\n    df, input_vocab, output_vocab, batch_size=64, in_column=\"EN\", out_column=\"PR\"\n):\n\n    n = len(df)\n    input_idxs = np.ones((n, MAX_LENGTH), dtype=np.int32) * input_vocab[\"<PAD>\"]\n    target_idxs = np.ones((n, MAX_LENGTH), dtype=np.int32) * output_vocab[\"<PAD>\"]\n\n    for idx, row in tqdm(df.iterrows(), total=n):\n        in_lang_idxs = process_sentence(input_vocab, row[in_column])\n        out_lang_idxs = process_sentence(output_vocab, row[out_column])\n\n        input_idxs[idx, : len(in_lang_idxs)] = in_lang_idxs\n        target_idxs[idx, : len(out_lang_idxs)] = out_lang_idxs\n\n    data = TensorDataset(\n        torch.LongTensor(input_idxs).to(device),\n        torch.LongTensor(target_idxs).to(device),\n    )\n\n    dataloader = DataLoader(data, batch_size=batch_size)\n    return dataloader","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:46.472780Z","iopub.status.busy":"2024-03-29T12:52:46.472520Z","iopub.status.idle":"2024-03-29T12:52:46.538584Z","shell.execute_reply":"2024-03-29T12:52:46.537793Z"},"papermill":{"duration":0.084565,"end_time":"2024-03-29T12:52:46.540590","exception":false,"start_time":"2024-03-29T12:52:46.456025","status":"completed"},"tags":[]},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Encoder Decoder RNN Model\n","metadata":{"papermill":{"duration":0.015503,"end_time":"2024-03-29T12:52:46.571635","exception":false,"start_time":"2024-03-29T12:52:46.556132","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch.nn as nn\n\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.gru(embedded)\n        return output, hidden","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:46.603816Z","iopub.status.busy":"2024-03-29T12:52:46.603519Z","iopub.status.idle":"2024-03-29T12:52:46.609915Z","shell.execute_reply":"2024-03-29T12:52:46.609097Z"},"papermill":{"duration":0.024427,"end_time":"2024-03-29T12:52:46.611755","exception":false,"start_time":"2024-03-29T12:52:46.587328","status":"completed"},"tags":[]},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(\n            batch_size, 1, dtype=torch.long, device=device\n        ).fill_(SOS_TOKEN_IDX)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden = self.forward_step(\n                decoder_input, decoder_hidden\n            )\n            decoder_outputs.append(decoder_output)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(\n                    -1\n                ).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        return (\n            decoder_outputs,\n            decoder_hidden,\n            None,\n        )  # return `None` for consistency in the training loop\n\n    def forward_step(self, input, hidden):\n        output = self.embedding(input)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.out(output)\n        return output, hidden","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:46.643526Z","iopub.status.busy":"2024-03-29T12:52:46.643237Z","iopub.status.idle":"2024-03-29T12:52:46.653478Z","shell.execute_reply":"2024-03-29T12:52:46.652780Z"},"papermill":{"duration":0.028431,"end_time":"2024-03-29T12:52:46.655328","exception":false,"start_time":"2024-03-29T12:52:46.626897","status":"completed"},"tags":[]},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Train\n","metadata":{"papermill":{"duration":0.014932,"end_time":"2024-03-29T12:52:46.685598","exception":false,"start_time":"2024-03-29T12:52:46.670666","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_epoch(\n    dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion\n):\n\n    total_loss = 0\n    for data in tqdm(dataloader):\n        input_tensor, target_tensor = data\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n\n        loss = criterion(\n            decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1)\n        )\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:46.717304Z","iopub.status.busy":"2024-03-29T12:52:46.717004Z","iopub.status.idle":"2024-03-29T12:52:46.723383Z","shell.execute_reply":"2024-03-29T12:52:46.722683Z"},"papermill":{"duration":0.024185,"end_time":"2024-03-29T12:52:46.725146","exception":false,"start_time":"2024-03-29T12:52:46.700961","status":"completed"},"tags":[]},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001):\n    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n    criterion = nn.NLLLoss()\n\n    for epoch in range(n_epochs):\n        loss = train_epoch(\n            train_dataloader,\n            encoder,\n            decoder,\n            encoder_optimizer,\n            decoder_optimizer,\n            criterion,\n        )\n        print(\"Epoch:\", epoch, \"loss:\", loss)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:46.757329Z","iopub.status.busy":"2024-03-29T12:52:46.756865Z","iopub.status.idle":"2024-03-29T12:52:46.762295Z","shell.execute_reply":"2024-03-29T12:52:46.761489Z"},"papermill":{"duration":0.023807,"end_time":"2024-03-29T12:52:46.764147","exception":false,"start_time":"2024-03-29T12:52:46.740340","status":"completed"},"tags":[]},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"hidden_size = 128\nbatch_size = 64\n\ntrain_dataloader = get_dataloader(\n    train_df[:10000],\n    batch_size=batch_size,\n    input_vocab=english_vocab,\n    output_vocab=port_vocab,\n)\n\nencoder = EncoderRNN(len(english_vocab), hidden_size).to(device)\ndecoder = DecoderRNN(hidden_size, len(port_vocab)).to(device)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:46.795446Z","iopub.status.busy":"2024-03-29T12:52:46.795181Z","iopub.status.idle":"2024-03-29T12:52:48.344415Z","shell.execute_reply":"2024-03-29T12:52:48.343443Z"},"papermill":{"duration":1.567422,"end_time":"2024-03-29T12:52:48.346740","exception":false,"start_time":"2024-03-29T12:52:46.779318","status":"completed"},"tags":[]},"execution_count":11,"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 10000/10000 [00:01<00:00, 8725.63it/s]\n"}]},{"cell_type":"code","source":"train(train_dataloader, encoder, decoder, n_epochs=5)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:52:48.381693Z","iopub.status.busy":"2024-03-29T12:52:48.381375Z","iopub.status.idle":"2024-03-29T12:54:15.956703Z","shell.execute_reply":"2024-03-29T12:54:15.955624Z"},"papermill":{"duration":87.595461,"end_time":"2024-03-29T12:54:15.958935","exception":false,"start_time":"2024-03-29T12:52:48.363474","status":"completed"},"tags":[]},"execution_count":12,"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 157/157 [00:18<00:00,  8.66it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 0 loss: 0.9608244647265999\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 157/157 [00:16<00:00,  9.33it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 1 loss: 0.21218722299405723\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 157/157 [00:16<00:00,  9.32it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 2 loss: 0.19913442546774626\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 157/157 [00:16<00:00,  9.27it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 3 loss: 0.19054425522020668\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 157/157 [00:16<00:00,  9.28it/s]"},{"name":"stdout","output_type":"stream","text":"Epoch: 4 loss: 0.1829584247557221\n"},{"name":"stderr","output_type":"stream","text":"\n"}]},{"cell_type":"markdown","source":"## Task\n\nTask is to translate sentences from English to Dutch with Encoder-Decoder RNN with attention mechanism\n","metadata":{"papermill":{"duration":0.128319,"end_time":"2024-03-29T12:54:16.164701","exception":false,"start_time":"2024-03-29T12:54:16.036382","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv(\"train.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:54:16.322091Z","iopub.status.busy":"2024-03-29T12:54:16.321011Z","iopub.status.idle":"2024-03-29T12:54:16.498502Z","shell.execute_reply":"2024-03-29T12:54:16.497495Z"},"papermill":{"duration":0.257654,"end_time":"2024-03-29T12:54:16.500717","exception":false,"start_time":"2024-03-29T12:54:16.243063","status":"completed"},"tags":[]},"execution_count":null,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>EN</th>\n","      <th>NL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>I couldn't understand his joke.</td>\n","      <td>Ik begreep zijn grap niet.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>There was nothing Tom could do about it.</td>\n","      <td>Er was niets dat Tom eraan kon doen.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>He has a hat on.</td>\n","      <td>Hij draagt een hoed.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Does that happen every time?</td>\n","      <td>Gebeurt dat elke keer?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Please don't run in the classroom.</td>\n","      <td>Alsjeblieft niet rennen in het klaslokaal.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                        EN  \\\n","0   0           I couldn't understand his joke.   \n","1   1  There was nothing Tom could do about it.   \n","2   2                          He has a hat on.   \n","3   3              Does that happen every time?   \n","4   4        Please don't run in the classroom.   \n","\n","                                           NL  \n","0                  Ik begreep zijn grap niet.  \n","1        Er was niets dat Tom eraan kon doen.  \n","2                        Hij draagt een hoed.  \n","3                      Gebeurt dat elke keer?  \n","4  Alsjeblieft niet rennen in het klaslokaal.  "]},"metadata":{}}]},{"cell_type":"code","source":"from torchtext.vocab import build_vocab_from_iterator\n\nSPECIAL_TOKENS = [\"<SOS>\", \"<EOS>\", \"<UNK>\", \"<PAD>\"]\nenglish_vocab = build_vocab_from_iterator(\n    preprocess(train_df[\"EN\"].values), special_first=True, specials=SPECIAL_TOKENS\n)\n\ndutch_vocab = build_vocab_from_iterator(\n    preprocess(train_df[\"NL\"].values), special_first=True, specials=SPECIAL_TOKENS\n)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:54:16.662751Z","iopub.status.busy":"2024-03-29T12:54:16.661993Z","iopub.status.idle":"2024-03-29T12:54:20.216419Z","shell.execute_reply":"2024-03-29T12:54:20.215367Z"},"papermill":{"duration":3.637408,"end_time":"2024-03-29T12:54:20.218468","exception":false,"start_time":"2024-03-29T12:54:16.581060","status":"completed"},"tags":[]},"execution_count":14,"outputs":[{"name":"stderr","output_type":"stream","text":"Building vocab: 100%|██████████| 68601/68601 [00:01<00:00, 41895.73it/s]\n\nBuilding vocab: 100%|██████████| 68601/68601 [00:01<00:00, 40395.78it/s]\n"}]},{"cell_type":"code","source":"print(\"Length of english vocab:\", len(english_vocab))\nprint(\"Length of dutch vocab:\", len(dutch_vocab))","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:54:20.387943Z","iopub.status.busy":"2024-03-29T12:54:20.387582Z","iopub.status.idle":"2024-03-29T12:54:20.392802Z","shell.execute_reply":"2024-03-29T12:54:20.391878Z"},"papermill":{"duration":0.092704,"end_time":"2024-03-29T12:54:20.395240","exception":false,"start_time":"2024-03-29T12:54:20.302536","status":"completed"},"tags":[]},"execution_count":15,"outputs":[{"name":"stdout","output_type":"stream","text":"Length of english vocab: 9494\n\nLength of dutch vocab: 13854\n"}]},{"cell_type":"markdown","source":"### Model\n","metadata":{"papermill":{"duration":0.079994,"end_time":"2024-03-29T12:54:20.556695","exception":false,"start_time":"2024-03-29T12:54:20.476701","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch.nn.functional as F\n\n\nclass BahdanauAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(BahdanauAttention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze(2).unsqueeze(1)\n\n        weights = F.softmax(scores, dim=-1)\n        context = torch.bmm(weights, keys)\n\n        return context, weights\n\n\nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n        super(AttnDecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.attention = BahdanauAttention(hidden_size)\n        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(\n            batch_size, 1, dtype=torch.long, device=device\n        ).fill_(SOS_TOKEN_IDX)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n        attentions = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            decoder_outputs.append(decoder_output)\n            attentions.append(attn_weights)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(\n                    -1\n                ).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        attentions = torch.cat(attentions, dim=1)\n\n        return decoder_outputs, decoder_hidden, attentions\n\n    def forward_step(self, input, hidden, encoder_outputs):\n        embedded = self.dropout(self.embedding(input))\n\n        query = hidden.permute(1, 0, 2)\n        context, attn_weights = self.attention(query, encoder_outputs)\n        input_gru = torch.cat((embedded, context), dim=2)\n\n        output, hidden = self.gru(input_gru, hidden)\n        output = self.out(output)\n\n        return output, hidden, attn_weights","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:54:20.721261Z","iopub.status.busy":"2024-03-29T12:54:20.720496Z","iopub.status.idle":"2024-03-29T12:54:20.737063Z","shell.execute_reply":"2024-03-29T12:54:20.736098Z"},"papermill":{"duration":0.102099,"end_time":"2024-03-29T12:54:20.739121","exception":false,"start_time":"2024-03-29T12:54:20.637022","status":"completed"},"tags":[]},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"hidden_size = 128\nbatch_size = 64\n\ntrain_dataloader = get_dataloader(\n    train_df,\n    batch_size=batch_size,\n    input_vocab=english_vocab,\n    output_vocab=dutch_vocab,\n    in_column=\"EN\",\n    out_column=\"NL\",\n)\n\nencoder = EncoderRNN(len(english_vocab), hidden_size).to(device)\ndecoder = AttnDecoderRNN(hidden_size, len(dutch_vocab)).to(device)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:54:20.902082Z","iopub.status.busy":"2024-03-29T12:54:20.901426Z","iopub.status.idle":"2024-03-29T12:54:30.849906Z","shell.execute_reply":"2024-03-29T12:54:30.848752Z"},"papermill":{"duration":10.032869,"end_time":"2024-03-29T12:54:30.852328","exception":false,"start_time":"2024-03-29T12:54:20.819459","status":"completed"},"tags":[]},"execution_count":17,"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 68601/68601 [00:09<00:00, 7005.69it/s]\n"}]},{"cell_type":"code","source":"train(train_dataloader, encoder, decoder, n_epochs=10)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T12:54:31.030059Z","iopub.status.busy":"2024-03-29T12:54:31.029442Z","iopub.status.idle":"2024-03-29T13:26:26.833545Z","shell.execute_reply":"2024-03-29T13:26:26.832591Z"},"papermill":{"duration":1915.894945,"end_time":"2024-03-29T13:26:26.835754","exception":false,"start_time":"2024-03-29T12:54:30.940809","status":"completed"},"tags":[]},"execution_count":18,"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 1072/1072 [03:12<00:00,  5.57it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 0 loss: 0.4511483043932648\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 1072/1072 [03:12<00:00,  5.58it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 1 loss: 0.27090134021283974\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 1072/1072 [03:11<00:00,  5.58it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 2 loss: 0.22069264835775343\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 1072/1072 [03:11<00:00,  5.59it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 3 loss: 0.1866087288554035\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 1072/1072 [03:11<00:00,  5.60it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 4 loss: 0.16060118323692413\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 1072/1072 [03:12<00:00,  5.56it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 5 loss: 0.1401216130592485\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 1072/1072 [03:10<00:00,  5.62it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 6 loss: 0.12376572213955779\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 1072/1072 [03:11<00:00,  5.61it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 7 loss: 0.11092277055383841\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 1072/1072 [03:10<00:00,  5.63it/s]\n"},{"name":"stdout","output_type":"stream","text":"Epoch: 8 loss: 0.10053218684312124\n"},{"name":"stderr","output_type":"stream","text":"100%|██████████| 1072/1072 [03:10<00:00,  5.62it/s]"},{"name":"stdout","output_type":"stream","text":"Epoch: 9 loss: 0.09200224798839929\n"},{"name":"stderr","output_type":"stream","text":"\n"}]},{"cell_type":"code","source":"torch.save(encoder.state_dict(), \"encoder.pt\")\ntorch.save(decoder.state_dict(), \"decoder.pt\")","metadata":{"execution":{"iopub.execute_input":"2024-03-29T13:26:28.724192Z","iopub.status.busy":"2024-03-29T13:26:28.723808Z","iopub.status.idle":"2024-03-29T13:26:28.762246Z","shell.execute_reply":"2024-03-29T13:26:28.761227Z"},"papermill":{"duration":1.011364,"end_time":"2024-03-29T13:26:28.764506","exception":false,"start_time":"2024-03-29T13:26:27.753142","status":"completed"},"tags":[]},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def predict(\n    encoder, decoder, dataloader, input_vocab=english_vocab, output_vocab=dutch_vocab\n):\n    with torch.no_grad():\n        predictions = []\n        for data in tqdm(dataloader):\n            input_tensor, _ = data\n            input_tensor = input_tensor.to(device)\n\n            encoder_outputs, encoder_hidden = encoder(input_tensor)\n            decoder_outputs, decoder_hidden, decoder_attn = decoder(\n                encoder_outputs, encoder_hidden\n            )\n\n            _, topi = decoder_outputs.topk(1)\n            decoded_ids = topi.squeeze()\n\n            for sentence in decoded_ids:\n                decoded_words = []\n                for idx in sentence:\n                    if idx.item() == EOS_TOKEN_IDX:\n                        break\n                    decoded_words.append(output_vocab.get_itos()[idx.item()])\n                predictions.append(\" \".join(decoded_words))\n    return predictions","metadata":{"execution":{"iopub.execute_input":"2024-03-29T13:26:30.661205Z","iopub.status.busy":"2024-03-29T13:26:30.660822Z","iopub.status.idle":"2024-03-29T13:26:30.668684Z","shell.execute_reply":"2024-03-29T13:26:30.667874Z"},"papermill":{"duration":0.925247,"end_time":"2024-03-29T13:26:30.670510","exception":false,"start_time":"2024-03-29T13:26:29.745263","status":"completed"},"tags":[]},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"test.csv\")\ntest_df[\"NL\"] = \"a\"","metadata":{"execution":{"iopub.execute_input":"2024-03-29T13:26:32.549410Z","iopub.status.busy":"2024-03-29T13:26:32.549017Z","iopub.status.idle":"2024-03-29T13:26:32.614493Z","shell.execute_reply":"2024-03-29T13:26:32.613697Z"},"papermill":{"duration":1.033005,"end_time":"2024-03-29T13:26:32.616748","exception":false,"start_time":"2024-03-29T13:26:31.583743","status":"completed"},"tags":[]},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_dataloader = get_dataloader(\n    test_df,\n    batch_size=batch_size,\n    input_vocab=english_vocab,\n    output_vocab=dutch_vocab,\n    in_column=\"EN\",\n    out_column=\"NL\",\n)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T13:26:34.556912Z","iopub.status.busy":"2024-03-29T13:26:34.555999Z","iopub.status.idle":"2024-03-29T13:26:35.421426Z","shell.execute_reply":"2024-03-29T13:26:35.420388Z"},"papermill":{"duration":1.876798,"end_time":"2024-03-29T13:26:35.423388","exception":false,"start_time":"2024-03-29T13:26:33.546590","status":"completed"},"tags":[]},"execution_count":22,"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 7623/7623 [00:00<00:00, 8951.17it/s]\n"}]},{"cell_type":"code","source":"encoder.eval()\ndecoder.eval()\n\npredictions = predict(encoder, decoder, test_dataloader)","metadata":{"execution":{"iopub.execute_input":"2024-03-29T13:26:37.313406Z","iopub.status.busy":"2024-03-29T13:26:37.312580Z","iopub.status.idle":"2024-03-29T13:27:33.207268Z","shell.execute_reply":"2024-03-29T13:27:33.206292Z"},"papermill":{"duration":56.87564,"end_time":"2024-03-29T13:27:33.209275","exception":false,"start_time":"2024-03-29T13:26:36.333635","status":"completed"},"tags":[]},"execution_count":23,"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 120/120 [00:55<00:00,  2.15it/s]\n"}]},{"cell_type":"code","source":"test_df[\"prediction\"] = predictions\ntest_df[[\"id\", \"prediction\"]]","metadata":{"execution":{"iopub.execute_input":"2024-03-29T13:27:35.140332Z","iopub.status.busy":"2024-03-29T13:27:35.139619Z","iopub.status.idle":"2024-03-29T13:27:35.169127Z","shell.execute_reply":"2024-03-29T13:27:35.168229Z"},"papermill":{"duration":0.978042,"end_time":"2024-03-29T13:27:35.171232","exception":false,"start_time":"2024-03-29T13:27:34.193190","status":"completed"},"tags":[]},"execution_count":24,"outputs":[]}]}